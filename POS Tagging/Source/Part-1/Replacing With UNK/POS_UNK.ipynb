{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "POS_UNKipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX1CbivA7Kbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx_ZIRcK7SLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# From utils.py\n",
        "def read_data(f):\n",
        "\twith open(f) as inp:\n",
        "\t\tlines = inp.readlines()\n",
        "\tdata = []\n",
        "\tfor line in lines:\n",
        "\t\tline = line.strip().split()\n",
        "\t\tsentence = []\n",
        "\t\tfor token in line:\n",
        "\t\t\ttoken = token.split('|')\n",
        "\t\t\tword = token[0]\n",
        "\t\t\ttag = token[1]\n",
        "\t\t\tsentence.append((word,tag))\n",
        "\t\tdata.append(sentence)\n",
        "\treturn data"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQbztoTH7Ujp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from utils.py\n",
        "def convert_data_for_training(data):\n",
        "\t#for d in data:\n",
        "\t#\ttokens = [t[0] for t in d]\n",
        "\t#\ttags = [t[1] for t in d]\n",
        "\treturn [([t[0] for t in d],[t[1] for t in d]) for d in data]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVJiEuOa7WtQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from pytorch_tagging.py\n",
        "TRAINING_FILE = \"./irish.train\"\n",
        "training_data = convert_data_for_training(read_data(TRAINING_FILE))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skYgHkV17aX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from utils.py\n",
        "def rare_words_to_UNK(tokenlist,keeplist, replaceToken='UNK'):\n",
        "\treturn [w if w in keeplist else replaceToken for w in tokenlist]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC1kkxqi7gln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from utils.py\n",
        "def substitute_with_UNK(data, n=1):\n",
        "\tword_frequency = {}\n",
        "\tdata_list = pd.DataFrame(data)\n",
        "\ttoken_list = data_list[0]\n",
        "\tfor token in token_list:\n",
        "\t\tfor word in token:\n",
        "\t\t\tif word in word_frequency:\n",
        "\t\t\t\tword_frequency[word]=word_frequency[word]+1\n",
        "\t\t\telse:\n",
        "\t\t\t\tword_frequency[word]=1\n",
        "\tfrequent_words=[key for key,value in word_frequency.items() if value >1]\n",
        "\ttoken_list = token_list.apply(rare_words_to_UNK, args=(frequent_words,'UNK'))\n",
        "\treturn list(zip(token_list,pd.DataFrame(data)[1]))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E_E_iDO7ifN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pytorch_taggin.py\n",
        "training_data_UNK = substitute_with_UNK(training_data)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5W4ONUv7lwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x# from pytorch_tagging.py \n",
        "def words_tags_indes(data):\n",
        "\tword_to_ix = {}#{'UNK':0}\n",
        "\tix_to_word = {}#{0:'UNK'}\n",
        "\ttag_to_ix = {}\n",
        "\tix_to_tag = {}\n",
        "\tfor sent, tags in data:\n",
        "\t\tfor word in sent:\n",
        "\t\t\tif word not in word_to_ix:\n",
        "\t\t\t\tword_to_ix[word] = len(word_to_ix)\n",
        "\t\t\t\tix_to_word[word_to_ix[word]] = word\n",
        "\t\tfor tag in tags:\n",
        "\t\t\tif tag not in tag_to_ix:\n",
        "\t\t\t\ttag_to_ix[tag] = len(tag_to_ix)\n",
        "\t\t\t\tix_to_tag[tag_to_ix[tag]] = tag\n",
        "\treturn word_to_ix,ix_to_word,ix_to_tag, tag_to_ix"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnxpmZXX7oLd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_to_ix_UNK, ix_to_word_UNK, ix_to_tag_UNK, tag_to_ix_UNK = words_tags_indes(training_data_UNK)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VAH6mTz7qih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pytorch_tagging.py\n",
        "torch.manual_seed(42)\n",
        "#Converts a sequence of words to a tensor of numerical values. \n",
        "def prepare_sequence(seq, to_ix):\n",
        "\tidxs = []\n",
        "\tfor word in seq:\n",
        "\t\tif word in to_ix:\n",
        "\t\t\tidxs.append(to_ix[word])\n",
        "\t\telse:\n",
        "\t\t\t idxs.append(to_ix['UNK'])\n",
        "\treturn torch.tensor(idxs, dtype=torch.long)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvaHh97P7r-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pytorch_tagging.py\n",
        "class LSTMTagger(nn.Module):\n",
        "\t# Class that defines our model\n",
        "\tdef __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "\t\tsuper(LSTMTagger, self).__init__()\n",
        "\t\tself.hidden_dim = hidden_dim\n",
        "\n",
        "\t\tself.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "\t\t# The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "\t\t# with dimensionality hidden_dim.\n",
        "\t\tself.lstm = nn.LSTM(embedding_dim, hidden_dim)#, bidirectional=True)\n",
        "\n",
        "\t\t# The linear layer that maps from hidden state space to tag space\n",
        "\t\tself.hidden2tag = nn.Linear(hidden_dim, tagset_size) #nn.Linear(hidden_dim*2, tagset_size)\n",
        "\n",
        "\t# This is the forward computation, which constructs the computation graph\n",
        "\tdef forward(self, sentence):\n",
        "\t\t# Get the embeddings\n",
        "\t\tembeds = self.word_embeddings(sentence)\n",
        "\t\t# put them through the LSTM and get its output\n",
        "\t\tlstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "\t\t# pass that output through the linnear layer\n",
        "\t\ttag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "\t\t# convert the logits to a log probability distribution\n",
        "\t\ttag_scores = F.log_softmax(tag_space, dim=1)\n",
        "\t\treturn tag_scores"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzcZyhBr7uM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pytorch_tagging.py\n",
        "# Hyperparameters\n",
        "EMBEDDING_DIM = 32\n",
        "HIDDEN_DIM = 32\n",
        "# DROPOUT = ?\n",
        "# LAYERS = ?"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xYmZDB_7vyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pytorch_taggin.py\n",
        "# Initialize the model\n",
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix_UNK), len(tag_to_ix_UNK))\n",
        "# Loss function to use\n",
        "loss_function = nn.NLLLoss()\n",
        "# Optimizer to use during training\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9I9g0vX7xIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pytorch_taggin.py\n",
        "# Training loop\n",
        "def train_model(model, n_epochs, training_data):\n",
        "\tfor epoch in range(n_epochs):  # normally you would NOT do 100 epochs, it is toy data\n",
        "\t\tprint(f\"Starting epoch {epoch}...\")\n",
        "\t\ttraining_losses = []\n",
        "\t\tfor sentence, tags in training_data:\n",
        "\t\t\t# Step 1. Remember that Pytorch accumulates gradients.\n",
        "\t\t\t# We need to clear them out before each instance\n",
        "\t\t\tmodel.zero_grad()\n",
        "\n",
        "\t\t\t# Step 2. Get our inputs ready for the network, that is, turn them into\n",
        "\t\t\t# Tensors of word indices.\n",
        "\t\t\t# Eventually I suggest you use the DataLoader modules\n",
        "\t\t\t# The batching can take place here\n",
        "\t\t\tsentence_in = prepare_sequence(sentence, word_to_ix_UNK)\n",
        "\t\t\ttargets = prepare_sequence(tags, tag_to_ix_UNK)\n",
        "\t\t\t# Step 3. Run our forward pass.\n",
        "\t\t\ttag_scores = model(sentence_in)\n",
        "\t\t\t# Step 4. Compute the loss, gradients, and update the parameters by\n",
        "\t\t\t#  calling optimizer.step()\n",
        "\t\t\tloss = loss_function(tag_scores, targets)\n",
        "\t\t\ttraining_losses.append(loss.item())\n",
        "\t\t\tloss.backward()\n",
        "\t\t\toptimizer.step()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWFVZ91T716q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "bf16bab9-25c3-4c9d-da13-ba9ba364a63f"
      },
      "source": [
        " train_model(model,10, training_data_UNK)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 0...\n",
            "Starting epoch 1...\n",
            "Starting epoch 2...\n",
            "Starting epoch 3...\n",
            "Starting epoch 4...\n",
            "Starting epoch 5...\n",
            "Starting epoch 6...\n",
            "Starting epoch 7...\n",
            "Starting epoch 8...\n",
            "Starting epoch 9...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eahlaBI2Pp7r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ad9d7d4-d57e-4049-ff9e-fb371fe79543"
      },
      "source": [
        "print(\"Saving model here\")\n",
        "path = \"./model_save_UNK.pth\"\n",
        "model_state = {'state_dict' : model.state_dict(),\n",
        "\t\t\t\t\t\t'optimizer' : optimizer.state_dict(),\n",
        "\t\t\t\t\t\t}\n",
        "torch.save(model_state, path)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model here\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJT5LsEhPsax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_checkpoint = torch.load(path)\n",
        "model.load_state_dict(model_checkpoint['state_dict'])\n",
        "optimizer.load_state_dict(model_checkpoint['optimizer'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaRBRHvy8bhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST_FILE = \"./irish.test\"\n",
        "test_data = convert_data_for_training(read_data(TEST_FILE))\n",
        "\n",
        "with torch.no_grad():\n",
        "\t# this will be the file to write the outputs\n",
        "\twith open(\"mymodel_output_irish.txt\", 'w') as op:\n",
        "\t\tfor instance in test_data:\n",
        "\t\t\t# Convert the test sentence into a word ID tensor\n",
        "\t\t\tinputs = prepare_sequence(instance[0], word_to_ix_UNK)\n",
        "\t\t\t# Forward pass\n",
        "\t\t\ttag_scores = model(inputs)\n",
        "\t\t\t# Find the tag with the highest probability in each position\n",
        "\t\t\toutputs = [int(np.argmax(ts)) for ts in tag_scores]\n",
        "\t\t\t# Prepare the output to be written in the same format as the test file (word|tag)\n",
        "\t\t\tformatted_output = ' '.join([f\"{word}|{ix_to_tag_UNK[tag_id]}\" for word,tag_id in zip(instance[0],outputs)])\n",
        "\t\t\t# Write the output\n",
        "\t\t\top.write(formatted_output + '\\n')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2Y4ob8c9kfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compute_accuracy\n",
        "def acc_read_data(f):\n",
        "\twith open(f) as inp:\n",
        "\t\tlines = inp.readlines()\n",
        "\tdata = []\n",
        "\tfor line in lines:\n",
        "\t\tline = line.strip().split()\n",
        "\t\tsentence = []\n",
        "\t\tfor token in line:\n",
        "\t\t\ttoken = token.split('|')\n",
        "\t\t\tword = token[0]\n",
        "\t\t\ttag = token[1]\n",
        "\t\t\tsentence.append((word,tag))\n",
        "\t\tdata.append(sentence)\n",
        "\treturn data"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7QjtNbZ9nhZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_accuracy(output, gold):\n",
        "\ttry:\n",
        "\t\tassert(len(output) == len(gold))\n",
        "\texcept:\n",
        "\t\tprint(\"Different number of lines in the two files!\")\n",
        "\t\treturn -1\n",
        "\n",
        "\tcount_correct = 0\n",
        "\tcount_total_tokens = 0\n",
        "\tfor o_sent,g_sent in zip(output,gold):\n",
        "\t\ttry:\n",
        "\t\t\tassert(len(o_sent)==len(g_sent))\n",
        "\t\texcept:\n",
        "\t\t\tprint(\"Different number of tokens in the two lines!\")\n",
        "\t\t\treturn -1\n",
        "\t\tcheck = [o_token[1] == g_token[1] for o_token,g_token in zip(o_sent,g_sent)]\n",
        "\t\tcount_correct += sum(check)\n",
        "\t\tcount_total_tokens += len(check)\n",
        "\treturn count_correct/count_total_tokens"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voYFMmSI9pZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = acc_read_data(\"./mymodel_output_irish.txt\")\n",
        "gold = acc_read_data(\"./irish.test\")\n",
        "acc = compute_accuracy(output,gold)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DslEAdcN9q4h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2a6e5e3-f158-4f6e-cacd-fcc02d345f50"
      },
      "source": [
        "print(acc)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8150163220892275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpwVpoUV9t05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}