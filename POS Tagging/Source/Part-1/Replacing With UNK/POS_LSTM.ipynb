{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "POS_LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pkd7um-__I4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWj3ZrLK_Mtr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# From utils.py\n",
        "def read_data(f):\n",
        "\twith open(f) as inp:\n",
        "\t\tlines = inp.readlines()\n",
        "\tdata = []\n",
        "\tfor line in lines:\n",
        "\t\tline = line.strip().split()\n",
        "\t\tsentence = []\n",
        "\t\tfor token in line:\n",
        "\t\t\ttoken = token.split('|')\n",
        "\t\t\tword = token[0]\n",
        "\t\t\ttag = token[1]\n",
        "\t\t\tsentence.append((word,tag))\n",
        "\t\tdata.append(sentence)\n",
        "\treturn data"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4R6Zhuk_Opg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from utils.py\n",
        "def convert_data_for_training(data):\n",
        "\t#for d in data:\n",
        "\t#\ttokens = [t[0] for t in d]\n",
        "\t#\ttags = [t[1] for t in d]\n",
        "\treturn [([t[0] for t in d],[t[1] for t in d]) for d in data]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYwqPaXb_i0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from pytorch_tagging.py\n",
        "TRAINING_FILE = \"./irish.train\"\n",
        "training_data = convert_data_for_training(read_data(TRAINING_FILE))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxOa_LUJ_Qjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from pytorch_tagging.py \n",
        "def words_tags_indes(data):\n",
        "\tword_to_ix = {'UNK':0}\n",
        "\tix_to_word = {0:'UNK'}\n",
        "\ttag_to_ix = {}\n",
        "\tix_to_tag = {}\n",
        "\tfor sent, tags in data:\n",
        "\t\tfor word in sent:\n",
        "\t\t\tif word not in word_to_ix:\n",
        "\t\t\t\tword_to_ix[word] = len(word_to_ix)\n",
        "\t\t\t\tix_to_word[word_to_ix[word]] = word\n",
        "\t\tfor tag in tags:\n",
        "\t\t\tif tag not in tag_to_ix:\n",
        "\t\t\t\ttag_to_ix[tag] = len(tag_to_ix)\n",
        "\t\t\t\tix_to_tag[tag_to_ix[tag]] = tag\n",
        "\treturn word_to_ix,ix_to_word,ix_to_tag, tag_to_ix"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtTqpIHt_V7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_to_ix,ix_to_word,ix_to_tag, tag_to_ix = words_tags_indes(training_data)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh5PRbWz_gL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pytorch_tagging.py\n",
        "torch.manual_seed(42)\n",
        "#Converts a sequence of words to a tensor of numerical values. \n",
        "def prepare_sequence(seq, to_ix):\n",
        "\tidxs = []\n",
        "\tfor word in seq:\n",
        "\t\tif word in to_ix:\n",
        "\t\t\tidxs.append(to_ix[word])\n",
        "\t\telse:\n",
        "\t\t\t idxs.append(to_ix['UNK'])\n",
        "\treturn torch.tensor(idxs, dtype=torch.long)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7UxE3Qn_rmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pytorch_tagging.py\n",
        "class LSTMTagger(nn.Module):\n",
        "\t# Class that defines our model\n",
        "\tdef __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "\t\tsuper(LSTMTagger, self).__init__()\n",
        "\t\tself.hidden_dim = hidden_dim\n",
        "\n",
        "\t\tself.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "\t\t# The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "\t\t# with dimensionality hidden_dim.\n",
        "\t\tself.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "\n",
        "\t\t# The linear layer that maps from hidden state space to tag space\n",
        "\t\tself.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "\t# This is the forward computation, which constructs the computation graph\n",
        "\tdef forward(self, sentence):\n",
        "\t\t# Get the embeddings\n",
        "\t\tembeds = self.word_embeddings(sentence)\n",
        "\t\t# put them through the LSTM and get its output\n",
        "\t\tlstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "\t\t# pass that output through the linnear layer\n",
        "\t\ttag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "\t\t# convert the logits to a log probability distribution\n",
        "\t\ttag_scores = F.log_softmax(tag_space, dim=1)\n",
        "\t\treturn tag_scores"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrmG3YXA_xxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pytorch_tagging.py\n",
        "# Hyperparameters\n",
        "EMBEDDING_DIM = 32\n",
        "HIDDEN_DIM = 32\n",
        "# DROPOUT = ?\n",
        "# LAYERS = ?"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "928mmSLO_0kb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pytorch_taggin.py\n",
        "# Initialize the model\n",
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
        "# Loss function to use\n",
        "loss_function = nn.NLLLoss()\n",
        "# Optimizer to use during training\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcORtMjw_5JH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pytorch_taggin.py\n",
        "# Training loop\n",
        "def train_model(model,n_epochs,training_data):\n",
        "\tfor epoch in range(n_epochs):  # normally you would NOT do 100 epochs, it is toy data\n",
        "\t\tprint(f\"Starting epoch {epoch}...\")\n",
        "\t\ttraining_losses = []\n",
        "\t\tfor sentence, tags in training_data:\n",
        "\t\t\t# Step 1. Remember that Pytorch accumulates gradients.\n",
        "\t\t\t# We need to clear them out before each instance\n",
        "\t\t\tmodel.zero_grad()\n",
        "\n",
        "\t\t\t# Step 2. Get our inputs ready for the network, that is, turn them into\n",
        "\t\t\t# Tensors of word indices.\n",
        "\t\t\t# Eventually I suggest you use the DataLoader modules\n",
        "\t\t\t# The batching can take place here\n",
        "\t\t\tsentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "\t\t\ttargets = prepare_sequence(tags, tag_to_ix)\n",
        "\t\t\t# Step 3. Run our forward pass.\n",
        "\t\t\ttag_scores = model(sentence_in)\n",
        "\t\n",
        "\t\t\t# Step 4. Compute the loss, gradients, and update the parameters by\n",
        "\t\t\t#  calling optimizer.step()\n",
        "\t\t\tloss = loss_function(tag_scores, targets)\n",
        "\t\t\ttraining_losses.append(loss.item())\n",
        "\t\t\tloss.backward()\n",
        "\t\t\toptimizer.step()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_FMdnbDAE8d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "d148b60e-19d4-44f0-b508-92cb02372a7c"
      },
      "source": [
        "train_model(model,10,training_data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 0...\n",
            "Starting epoch 1...\n",
            "Starting epoch 2...\n",
            "Starting epoch 3...\n",
            "Starting epoch 4...\n",
            "Starting epoch 5...\n",
            "Starting epoch 6...\n",
            "Starting epoch 7...\n",
            "Starting epoch 8...\n",
            "Starting epoch 9...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtBbIEWgPVto",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15ec5de6-9c2b-48c4-83b2-b957f65331a3"
      },
      "source": [
        "print(\"Saving model here\")\n",
        "path = \"./model_save.pth\"\n",
        "model_state = {'state_dict' : model.state_dict(),\n",
        "\t\t\t\t\t\t'optimizer' : optimizer.state_dict(),\n",
        "\t\t\t\t\t\t}\n",
        "torch.save(model_state, path)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model here\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYMhn0QzPcb3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_checkpoint = torch.load(path)\n",
        "model.load_state_dict(model_checkpoint['state_dict'])\n",
        "optimizer.load_state_dict(model_checkpoint['optimizer'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO3AIZRGAPDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST_FILE = \"./irish.test\"\n",
        "test_data = convert_data_for_training(read_data(TEST_FILE))\n",
        "\n",
        "with torch.no_grad():\n",
        "\t# this will be the file to write the outputs\n",
        "\twith open(\"mymodel_output_irish.txt\", 'w') as op:\n",
        "\t\tfor instance in test_data:\n",
        "\t\t\t# Convert the test sentence into a word ID tensor\n",
        "\t\t\tinputs = prepare_sequence(instance[0], word_to_ix)\n",
        "\t\t\t# Forward pass\n",
        "\t\t\ttag_scores = model(inputs)\n",
        "\t\t\t# Find the tag with the highest probability in each position\n",
        "\t\t\toutputs = [int(np.argmax(ts)) for ts in tag_scores]\n",
        "\t\t\t# Prepare the output to be written in the same format as the test file (word|tag)\n",
        "\t\t\tformatted_output = ' '.join([f\"{word}|{ix_to_tag[tag_id]}\" for word,tag_id in zip(instance[0],outputs)])\n",
        "\t\t\t# Write the output\n",
        "\t\t\top.write(formatted_output + '\\n')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlDKQBoLASex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compute_accuracy\n",
        "def acc_read_data(f):\n",
        "\twith open(f) as inp:\n",
        "\t\tlines = inp.readlines()\n",
        "\tdata = []\n",
        "\tfor line in lines:\n",
        "\t\tline = line.strip().split()\n",
        "\t\tsentence = []\n",
        "\t\tfor token in line:\n",
        "\t\t\ttoken = token.split('|')\n",
        "\t\t\tword = token[0]\n",
        "\t\t\ttag = token[1]\n",
        "\t\t\tsentence.append((word,tag))\n",
        "\t\tdata.append(sentence)\n",
        "\treturn data"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq3oECUDAVU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_accuracy(output, gold):\n",
        "\ttry:\n",
        "\t\tassert(len(output) == len(gold))\n",
        "\texcept:\n",
        "\t\tprint(\"Different number of lines in the two files!\")\n",
        "\t\treturn -1\n",
        "\n",
        "\tcount_correct = 0\n",
        "\tcount_total_tokens = 0\n",
        "\tfor o_sent,g_sent in zip(output,gold):\n",
        "\t\ttry:\n",
        "\t\t\tassert(len(o_sent)==len(g_sent))\n",
        "\t\texcept:\n",
        "\t\t\tprint(\"Different number of tokens in the two lines!\")\n",
        "\t\t\treturn -1\n",
        "\t\tcheck = [o_token[1] == g_token[1] for o_token,g_token in zip(o_sent,g_sent)]\n",
        "\t\tcount_correct += sum(check)\n",
        "\t\tcount_total_tokens += len(check)\n",
        "\treturn count_correct/count_total_tokens"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2pMXWGiAXpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = acc_read_data(\"./mymodel_output_irish.txt\")\n",
        "gold = acc_read_data(\"./irish.test\")\n",
        "acc = compute_accuracy(output,gold)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rGEe_gbAZep",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7fb8ecaf-a2d8-4ab5-f19b-1926fa04f1b3"
      },
      "source": [
        "acc"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7950341280047483"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmuFNkbC2LFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}