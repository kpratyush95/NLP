{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pos_Batching.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOSr12RM8y8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import sys\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM9Fwzs-Gl3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# From utils.py\n",
        "def read_data(f):\n",
        "\twith open(f) as inp:\n",
        "\t\tlines = inp.readlines()\n",
        "\tdata = []\n",
        "\tfor line in lines:\n",
        "\t\tline = line.strip().split()\n",
        "\t\tsentence = []\n",
        "\t\tfor token in line:\n",
        "\t\t\ttoken = token.split('|')\n",
        "\t\t\tword = token[0]\n",
        "\t\t\ttag = token[1]\n",
        "\t\t\tsentence.append((word,tag))\n",
        "\t\tdata.append(sentence)\n",
        "\treturn data"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c175kWOZGp4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from utils.py\n",
        "def convert_data_for_training(data):\n",
        "\t#for d in data:\n",
        "\t#\ttokens = [t[0] for t in d]\n",
        "\t#\ttags = [t[1] for t in d]\n",
        "\treturn [([t[0] for t in d],[t[1] for t in d]) for d in data]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqrjEWiBGr_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from pytorch_tagging.py\n",
        "TRAINING_FILE = \"./irish.train\"\n",
        "training_data = convert_data_for_training(read_data(TRAINING_FILE))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph52sMt_L3KC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from pytorch_tagging.py \n",
        "def words_tags_indes(data):\n",
        "\tword_to_ix = {'PAD': 0 ,'UNK':1}\n",
        "\tix_to_word = {0:'PAD',1:'UNK'}\n",
        "\ttag_to_ix = {'PAD':0}\n",
        "\tix_to_tag = {0:'PAD'}\n",
        "\tfor sent, tags in data:\n",
        "\t\tfor word in sent:\n",
        "\t\t\tif word not in word_to_ix:\n",
        "\t\t\t\tword_to_ix[word] = len(word_to_ix)\n",
        "\t\t\t\tix_to_word[word_to_ix[word]] = word\n",
        "\t\tfor tag in tags:\n",
        "\t\t\tif tag not in tag_to_ix:\n",
        "\t\t\t\ttag_to_ix[tag] = len(tag_to_ix)\n",
        "\t\t\t\tix_to_tag[tag_to_ix[tag]] = tag\n",
        "\treturn word_to_ix,ix_to_word,ix_to_tag, tag_to_ix"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNUI2DxrL4l3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_to_ix,ix_to_word,ix_to_tag, tag_to_ix = words_tags_indes(training_data)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf5G7jMkL9WS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pytorch_tagging.py\n",
        "torch.manual_seed(42)\n",
        "#Converts a sequence of words to a tensor of numerical values. \n",
        "def prepare_sequence(seq, to_ix):\n",
        "\tidxs = []\n",
        "\tfor word in seq:\n",
        "\t\tif word in to_ix:\n",
        "\t\t\tidxs.append(to_ix[word])\n",
        "\t\telse:\n",
        "\t\t\t idxs.append(to_ix['UNK'])\n",
        "\treturn torch.tensor(idxs, dtype=torch.long)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpSuRLXR5guB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #pytorch_tagging.py\n",
        "# # See what the scores are before training\n",
        "# # Note that element i,j of the output is the score for tag j for word i.\n",
        "# # Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
        "# with torch.no_grad():\n",
        "#   #changes here\n",
        "#   for index in range(len(training_data)):\n",
        "#     #changes here\n",
        "# \t  inputs = prepare_sequence(training_data[index][0], word_to_ix)\n",
        "# \t  tag_scores = model(inputs)\n",
        "# \t  print(tag_scores)\n",
        "#    #changes here\n",
        "# \t  for i,word in enumerate(training_data[index][0]):\n",
        "# \t\t  j = int(np.argmax(tag_scores[i]))\n",
        "# \t\t  print(f\"\\t{word}|{ix_to_tag[j]}\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd6p7d3OCF20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_collate(training_data):\n",
        "\tsentence_array = []\n",
        "\ttag_array = []\n",
        "\tfor sentence, tags in training_data:\n",
        "\t\tsentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "\t\ttargets = prepare_sequence(tags, tag_to_ix)\n",
        "\t\tsentence_array.append(sentence_in)\n",
        "\t\ttag_array.append(targets)\n",
        "\tsentence_pad = pad_sequence(sentence_array, batch_first= True, padding_value= 0.0)\n",
        "\ttag_pad = pad_sequence(tag_array, batch_first= True, padding_value= 0.0)\n",
        "\treturn sentence_pad, tag_pad \n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRJQOrx7G2N2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_loader = DataLoader(dataset=training_data, batch_size=32, shuffle=True, collate_fn=pad_collate)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nooLS8BFvDDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pytorch_tagging.py\n",
        "class LSTMTagger(nn.Module):\n",
        "\t# Class that defines our model\n",
        "\tdef __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size, batch_size):\n",
        "\t\tsuper(LSTMTagger, self).__init__()\n",
        "\t\tself.hidden_dim = hidden_dim\n",
        "\n",
        "\t\tself.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "\t\t# The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "\t\t# with dimensionality hidden_dim.\n",
        "\t\tself.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first= True)\n",
        "\n",
        "\t\t# The linear layer that maps from hidden state space to tag space\n",
        "\t\tself.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "\t# This is the forward computation, which constructs the computation graph\n",
        "\tdef forward(self, sentence):\n",
        "\t\t# Get the embeddings\n",
        "\t\tembeds = self.word_embeddings(sentence)\n",
        "\t\t# put them through the LSTM and get its output\n",
        "\t\t# lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "\t\t# # pass that output through the linnear layer\n",
        "\t\t# tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "\t\t# # convert the logits to a log probability distribution\n",
        "\t\t# tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "\t\t# return tag_scores\n",
        "\t\tbatch_size = sentence.size(0)\n",
        "\t\tsentence = sentence.long()\n",
        "\t\tembeds = self.word_embeddings(sentence)\n",
        "\t\tlstm_out, _ = self.lstm(embeds)\n",
        "\t\tlstm_out = lstm_out.contiguous().reshape(-1, self.hidden_dim)\n",
        "\t\ttag_space = self.hidden2tag(lstm_out)\n",
        "\t\ttag_scores = F.log_softmax(tag_space, dim=1)\n",
        "\t\treturn tag_scores"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1zZ2lBJ-POg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pytorch_tagging.py\n",
        "# Hyperparameters\n",
        "EMBEDDING_DIM = 32\n",
        "HIDDEN_DIM = 32\n",
        "BATCH_SIZE = 32\n",
        "# DROPOUT = ?\n",
        "# LAYERS = ?"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuDbteAJ-zRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pytorch_taggin.py\n",
        "# Initialize the model\n",
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix),BATCH_SIZE)\n",
        "# Loss function to use\n",
        "loss_function = nn.NLLLoss()\n",
        "# Optimizer to use during training\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1V4CK4i-5xV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pytorch_taggin.py\n",
        "# Training loop\n",
        "def train_model(model,n_epochs, patience, training_data):\n",
        "\tfor epoch in range(n_epochs):  # normally you would NOT do 100 epochs, it is toy data\n",
        "\t\tprint(f\"Starting epoch {epoch}...\")\n",
        "\t\ttraining_losses = []\n",
        "\t\tfor sentence, tags in training_data:\n",
        "\t\t\t# Step 1. Remember that Pytorch accumulates gradients.\n",
        "\t\t\t# We need to clear them out before each instance\n",
        "\t\t\tmodel.zero_grad()\n",
        "\n",
        "\t\t\t# Step 2. Get our inputs ready for the network, that is, turn them into\n",
        "\t\t\t# Tensors of word indices.\n",
        "\t\t\t# Eventually I suggest you use the DataLoader modules\n",
        "\t\t\t# The batching can take place here\n",
        "\t\t\t#sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "\t\t\t#targets = prepare_sequence(tags, tag_to_ix)\n",
        "\t\t\t# Step 3. Run our forward pass.\n",
        "\t\t\ttag_scores = model(sentence)\n",
        "\t\t\t# Step 4. Compute the loss, gradients, and update the parameters by\n",
        "\t\t\t#  calling optimizer.step()\n",
        "\t\t\tloss = loss_function(tag_scores, tags.flatten())\n",
        "\t\t\ttraining_losses.append(loss.item())\n",
        "\t\t\tloss.backward()\n",
        "\t\t\toptimizer.step()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmNd_KOY_pGJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "50e8c020-bfce-4e17-ff18-f1a75f1dda0e"
      },
      "source": [
        " train_model(model,20, 8, train_data_loader)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 0...\n",
            "Starting epoch 1...\n",
            "Starting epoch 2...\n",
            "Starting epoch 3...\n",
            "Starting epoch 4...\n",
            "Starting epoch 5...\n",
            "Starting epoch 6...\n",
            "Starting epoch 7...\n",
            "Starting epoch 8...\n",
            "Starting epoch 9...\n",
            "Starting epoch 10...\n",
            "Starting epoch 11...\n",
            "Starting epoch 12...\n",
            "Starting epoch 13...\n",
            "Starting epoch 14...\n",
            "Starting epoch 15...\n",
            "Starting epoch 16...\n",
            "Starting epoch 17...\n",
            "Starting epoch 18...\n",
            "Starting epoch 19...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_tmY6G3QY7O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8711efde-6422-4c28-ed6f-896457c593a5"
      },
      "source": [
        "print(\"Saving model here\")\n",
        "path = \"./model_save_Batch.pth\"\n",
        "model_state = {'state_dict' : model.state_dict(),\n",
        "\t\t\t\t\t\t'optimizer' : optimizer.state_dict(),\n",
        "\t\t\t\t\t\t}\n",
        "torch.save(model_state, path)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model here\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqK63GAZQ54v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_checkpoint = torch.load(path)\n",
        "model.load_state_dict(model_checkpoint['state_dict'])\n",
        "optimizer.load_state_dict(model_checkpoint['optimizer'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzxUSJfzNddf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST_FILE = \"./irish.test\"\n",
        "test_data = convert_data_for_training(read_data(TEST_FILE))\n",
        "\n",
        "with torch.no_grad():\n",
        "\t# this will be the file to write the outputs\n",
        "\twith open(\"mymodel_output_irish.txt\", 'w') as op:\n",
        "\t\tfor instance in test_data:\n",
        "\t\t\t# Convert the test sentence into a word ID tensor\n",
        "\t\t\tinputs = torch.LongTensor(prepare_sequence(instance[0], word_to_ix))\n",
        "\t\t\t#inputs = prepare_sequence(instance[0], word_to_ix)\n",
        "\t\t\t# Forward pass\n",
        "\t\t\ttag_scores = model(inputs.reshape(-1,inputs.shape[0]))\n",
        "\t\t\t# Find the tag with the highest probability in each position\n",
        "\t\t\toutputs = [int(np.argmax(ts)) for ts in tag_scores]\n",
        "\t\t\t# Prepare the output to be written in the same format as the test file (word|tag)\n",
        "\t\t\tformatted_output = ' '.join([f\"{word}|{ix_to_tag[tag_id]}\" for word,tag_id in zip(instance[0],outputs)])\n",
        "\t\t\t# Write the output\n",
        "\t\t\top.write(formatted_output + '\\n')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opB6o9JioaWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compute_accuracy\n",
        "def acc_read_data(f):\n",
        "\twith open(f) as inp:\n",
        "\t\tlines = inp.readlines()\n",
        "\tdata = []\n",
        "\tfor line in lines:\n",
        "\t\tline = line.strip().split()\n",
        "\t\tsentence = []\n",
        "\t\tfor token in line:\n",
        "\t\t\ttoken = token.split('|')\n",
        "\t\t\tword = token[0]\n",
        "\t\t\ttag = token[1]\n",
        "\t\t\tsentence.append((word,tag))\n",
        "\t\tdata.append(sentence)\n",
        "\treturn data"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhjMTYk_q7ZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_accuracy(output, gold):\n",
        "\ttry:\n",
        "\t\tassert(len(output) == len(gold))\n",
        "\texcept:\n",
        "\t\tprint(\"Different number of lines in the two files!\")\n",
        "\t\treturn -1\n",
        "\n",
        "\tcount_correct = 0\n",
        "\tcount_total_tokens = 0\n",
        "\tfor o_sent,g_sent in zip(output,gold):\n",
        "\t\ttry:\n",
        "\t\t\tassert(len(o_sent)==len(g_sent))\n",
        "\t\texcept:\n",
        "\t\t\tprint(\"Different number of tokens in the two lines!\")\n",
        "\t\t\treturn -1\n",
        "\t\tcheck = [o_token[1] == g_token[1] for o_token,g_token in zip(o_sent,g_sent)]\n",
        "\t\tcount_correct += sum(check)\n",
        "\t\tcount_total_tokens += len(check)\n",
        "\treturn count_correct/count_total_tokens"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eAb8BmKrMXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = acc_read_data(\"./mymodel_output_irish.txt\")\n",
        "gold = acc_read_data(\"./irish.test\")\n",
        "acc = compute_accuracy(output,gold)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM2Em_YqrOMS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d331b7bf-4b8c-4599-d239-22c938f4db8e"
      },
      "source": [
        "acc"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42922148580472846"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHUcdVinrO4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}